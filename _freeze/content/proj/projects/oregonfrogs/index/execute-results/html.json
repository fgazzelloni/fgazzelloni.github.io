{
  "hash": "2914004153680398a09482588177e9e2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Oregon spotted a frog: Rana Pretiosa'\ndate: 2022-10-30\nexcerpt: Machine Learning with mlr3\nimages: \nseries: package\ntags:\n  - rstats\n  - mlr3\ncategories: \n  - \"Machine Learning\" \n  - \"mlr3\"\nlayout: single\npage-layout: full\nexecute: \n  eval: false\n---\n\n#### Updated June 2023\n\n# Overview\n\n::::: columns\n::: {.column width=\"80%\"}\nI made a package! Looking for data to use for one of my data visualization I stomped into this data about frogs in Oregon (US) and realized that it was very interesting for making both classification and regression models. So, I wrapped the data into a package, and even if it is still a work in progress I started using it for practicing **machine learning** algorithms.\n\nMore info about it will follow. For now this project is all about how to use `{mlr3}` package for analysing and predicting data. **mlr3** is a machine learning **ecosystem**, it provides a unified interface to use different machine learning models in R.\n:::\n\n::: {.column width=\"20%\"}\n![](featured.png)\n:::\n:::::\n\nLet's load the libraries, and start using **mlr3** with **oregonfrogs** data!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(mlr3)\n# remotes::install_github(\"mlr-org/mlr3spatiotempcv\")\nlibrary(mlr3spatiotempcv)\nlibrary(mlr3learners) # needed to initiate a new learner (such as classif.ranger)\n# remotes::install_github(\"mlr-org/mlr3extralearners\")\nlibrary(mlr3extralearners)\nlibrary(ranger)\n# install.packages(\"apcluster\")\n# remotes::install_github(\"mlr-org/mlr3proba\")\nlibrary(\"mlr3viz\")\n```\n:::\n\n\nTo install `{oregonfrogs}`, which is still in its development version you need to install it from github:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# remotes::install_github(\"fgazzelloni/oregonfrogs\")\nlibrary(oregonfrogs)\n```\n:::\n\n\nI changed the name of the dataset to **oregonfrogs**, so now is `oregonfrogs::oregonfrogs` also added some functions, made some modifications, and left the raw data (`oregonfrogs_raw`) available.\n\nHere, I take some selected variables which I'll use in the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noregonfrogs_raw %>%\n  head(3) %>%\n  select(3:4, 6:8, 10:11)\n```\n:::\n\n\nIt's a practical use to change the *utm* coordinates into *longlat*. The package include these changes in the *oregonfrogs* dataset. As well as, I added a couple of functions that let the user switch back and forth between coordinate systems, `utm_to_longlat` and `longlat_to_utm`.\n\nThis is basically what the `utm_to_longlat()` function does:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noregonfrogs <- oregonfrogs_raw %>%\n  dplyr::select(UTME_83, UTMN_83) %>%\n  sf::st_as_sf(coords = c(1, 2),\n               crs = \"+proj=utm +zone=10\") %>%\n  sf::st_transform(crs = \"+proj=longlat +datum=WGS84\")  %>%\n  sf::st_coordinates() %>%\n  cbind(oregonfrogs_raw) %>%\n  mutate(\n    SurveyDate = as.Date(SurveyDate, \"%m/%d/%Y\"),\n    month = lubridate::month(SurveyDate),\n    Water = as.factor(Water)\n  ) %>%\n  select(-SurveyDate,-UTME_83,-UTMN_83,-Site)\n```\n:::\n\n\nAnd here is a spec of the two systems in comparison for the **oregonfrogs** data:\n\n\n::: {.cell}\n\n:::\n\n\n### Set a Task\n\nThe **mlr3 package** provides a `task()` function, which allows to set the data to use inside the selected model.\n\nMore specifically, here is used `mlr3spatiotempcv::TaskClassifST()` specific for **spatial classification** modeling tasks.\n\nAmong the function's *options*, there are:\n\n-   *id*: the identification of the location,\n-   *backend*: the data to use in the model\n-   *target*: the response variable\n-   ...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask = mlr3spatiotempcv::TaskClassifST$new(\n  id = \"lake\",\n  backend = mlr3::as_data_backend(oregonfrogs),\n  target = \"Water\",\n  #positive = \"FALSE\",  ### ????\n  coordinate_names = c(\"X\", \"Y\"),\n  coords_as_features = TRUE,\n  crs = \"+proj=longlat +datum=WGS84\"   # \"+proj=utm +zone=10\"\n)\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n### Set the Learner\n\nThe second step is to set the **learner**: `mlr3::lrn()`\n\nThis is the model type and prediction outcome type:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model type\n# mlr_learners$get(\"classif.ranger\")\nlearner = mlr3::lrn(\"classif.ranger\", predict_type = \"prob\")\n# learner$help()\nlearner\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner$param_set\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner$train(task)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlearner$model\n```\n:::\n\n\n### Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction <- learner$predict_newdata(oregonfrogs)\nmeasure = msr(\"classif.acc\")\nprediction$score(measure)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction$confusion\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmlr3viz::autoplot(prediction)\n```\n:::\n\n\n### Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# resampling\nresampling = mlr3::rsmp(\"repeated_spcv_coords\",\n                        folds = 5,\n                        repeats = 100)\nresampling\n```\n:::\n\n\nA **logging record** can be set for debugging in case model crashes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n```\n:::\n\n\nParallelization:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparallelly::availableCores()\nset_threads(learner)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit resamples\ntime = Sys.time()\nrr_spcv_ranger = mlr3::resample(task = task,\n                                learner = learner,\n                                resampling = resampling)\nSys.time() - time\n```\n:::\n\n\nTime difference of 48.01483 secs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr_spcv_ranger\nrr_spcv_ranger$score() \n```\n:::\n\n\n### Model evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# accuracy\nscore_spcv_ranger = rr_spcv_ranger$score(measure = mlr3::msr(\"classif.acc\")) %>%\n  select(task_id, learner_id, resampling_id, classif.acc)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# avg accuracy\nmean(score_spcv_ranger$classif.acc) %>%\n  round(2)  # 0.64\n```\n:::\n\n\n## Machine Learning\n\n### Tuning: Tweaking the hyperparameters of the learner\n\nIn **random forests**, the hyperparameters *mtry*, *min.node.size* and *sample.fraction* determine the degree of randomness, and should be tuned. This is when **machine learning** comes into play.\n\nHyperparameters:\n\n-   **mtry** indicates how many predictor variables should be used in each tree\n-   **sample.fraction** parameter specifies the fraction of observations to be used in each tree\n-   **min.node.size** parameter indicates the number of observations a terminal node should at least have\n\nsource: <https://geocompr.robinlovelace.net/eco.html>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#### tuning\ntune_level = mlr3::rsmp(\"spcv_coords\", folds = 5)\n\nterminator = mlr3tuning::trm(\"evals\", n_evals = 50)\n\ntuner = mlr3tuning::tnr(\"random_search\")\n```\n:::\n\n\n#### Search space\n\nTo specify tuning limits `paradox::ps()` is used:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsearch_space =\n  paradox::ps(\n    mtry = paradox::p_int(lower = 1,\n                          upper = ncol(task$data()) - 1),\n    sample.fraction = paradox::p_dbl(lower = 0.2,\n                                     upper = 0.9),\n    min.node.size = paradox::p_int(lower = 1,\n                                   upper = 10)\n  )\nsearch_space\n```\n:::\n\n\n#### Automation\n\nAutomated tuning specification via the `mlr3tuning::AutoTuner()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautotuner_rf =\n  mlr3tuning::AutoTuner$new(\n    learner = learner,\n    store_benchmark_result = TRUE,\n    resampling = mlr3::rsmp(\"spcv_coords\",\n                            folds = 5),\n    # spatial partitioning\n    measure = mlr3::msr(\"classif.acc\"),\n    # performance measure\n    terminator = mlr3tuning::trm(\"evals\",\n                                 n_evals = 50),\n    # specify 50 iterations\n    search_space = search_space,\n    # predefined hyperparameter search space\n    tuner = mlr3tuning::tnr(\"random_search\") # specify random search\n  )\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hyperparameter tuning\ntime = Sys.time()\n\nset.seed(0412022)\nautotuner_rf$train(task)\n\nSys.time() - time\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautotuner_rf$tuning_result\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautotuner_rf$predict(task)\n# pred = terra::predict(..., model = autotuner_rf, fun = predict)\n\n# save.image(\"data/oregonfrogs_mlr3.RData\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- autotuner_rf$predict(task)\nautoplot(res)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres %>%\n  fortify() %>%\n  pivot_longer(cols = starts_with(\"prob\"),\n               names_to = \"prob_type\",\n               values_to = \"prob\") %>%\n  mutate(prob_type = gsub(\"prob.\", \"\", prob_type)) %>%\n  ggplot(aes(prob, group = prob_type, fill = prob_type)) +\n  geom_density(alpha = 0.5) +\n  facet_wrap(vars(prob_type), scales = \"free\") +\n  labs(fill = \"Water Type\", x = \"Probability\", y = \"Density\") +\n  scale_fill_viridis_d() +\n  theme_bw()\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}