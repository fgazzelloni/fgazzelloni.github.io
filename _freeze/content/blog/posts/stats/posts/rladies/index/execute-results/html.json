{
  "hash": "ee170fbb2ac955fc798c266c876b3065",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"R-Ladies Events Stats\"\nexcerpt: \"Statistics\"\ndate: 2024-03-12\ndraft: false\nimages: featured.png\nseries:\ncategories: text-analysis\nlayout: single\npage-layout: full\nexecute: \n  eval: false\n---\n\n## Overview\n\n::: columns\n::: {.column width=\"80%\"}\nLet's scrap the R-Ladies chapters events from Meetup.com We can use the `{meetupr}` package.\n\n```         \nurlname <- c(\"rladies-paris\",\"rladies-rome\")\nevents <- purrr::map(urlname,get_events)\ndat <- dplyr::bind_rows(events)\n```\n:::\n\n::: {.column width=\"20%\"}\n![RLadies Wordcloud](featured.png)\n:::\n:::\n\nLoad necessary libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(meetupr)\n  library(jsonlite)\n  library(tidyverse)\n  library(stringr)\n  library(tidytext)\n  library(wordcloud)\n  library(topicmodels)\n  library(broom)\n  library(scales)\n})\n\n\ntheme_set(theme_bw())\n```\n:::\n\n\n### R-Ladies Rome Events\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurlname <- \"rladies-rome\"\nevents <- get_events(urlname)\ndplyr::arrange(events, desc(time))%>%\n  head()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurlname <- c(\"rladies-paris\",\"rladies-rome\")\nevents <- purrr::map(urlname,get_events)\ndat <- dplyr::bind_rows(events)\ndat%>%\n  mutate(link=gsub(\"https://www.meetup.com/\",\"\",link),\n         chapter=stringr::str_extract(link, \"^rladies(.+?)/\"),\n         chapter=gsub(\"/\",\"\",chapter))%>%\n  count(chapter)\n```\n:::\n\n\n### All Chapters Events\n\nTo do it for all chapters on meetup, we need the list of the chapters from the rladies github archive.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- jsonlite::fromJSON('https://raw.githubusercontent.com/rladies/meetup_archive/main/data/events.json')\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchapter <- data %>%\n  count(group_urlname)%>%\n  filter(!str_detect(group_urlname,\"@\"))\nchapters <- chapter$group_urlname\n\nevents <- purrr::map(chapters,get_events)\n# saveRDS(events,\"events.rds\")\n# another way\n# x <- lapply(paths, func)\n# res <- dplyr::bind_rows(x)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(events[1])%>%head()\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dplyr::bind_rows(events)\n# saveRDS(dat,\"dat.rds\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1 <- dat%>% \n  mutate(link=gsub(\"https://www.meetup.com/\",\"\",link),\n         chapter=stringr::str_extract(link, \"^rladies(.+?)/\"),\n         chapter=gsub(\"/\",\"\",chapter))%>%\n  relocate(chapter)\n\n# saveRDS(dat1,\"dat1.rds\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 <- dat1%>%\n  select(time,chapter,title,going,venue_city,\n         venue_lon,venue_lat,venue_state,venue_country)%>%\n  mutate(time=as.Date(time))%>%\n  arrange(desc(going))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2%>%\n  mutate(year=year(time),.after = time)%>%\n  pull(year)%>%\n  summary(year)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3 <- dat2%>%\n  tidytext::unnest_tokens(word, title,drop = F)%>%\n  select(chapter,title,going,word)%>% \n  anti_join(get_stopwords())%>%\n  filter(!str_length(word)<=3)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3%>%\n  count(word, sort = TRUE) %>%\n  with(wordcloud::wordcloud(word, n, max.words = 100))\n```\n:::\n\n\n### Latent Dirichlet Allocation with the topicmodels package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchapters_dtm <- dat3 %>%\n  count(title, word, sort = TRUE)%>%\n  cast_dtm(title, word, n)\n\nchapters_dtm\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchapters_lda <- topicmodels::LDA(chapters_dtm, \n                    k = 4, \n                    control = list(seed = 1234))\nchapters_lda_td <- tidy(chapters_lda)\nchapters_lda_td\ntop_terms <- chapters_lda_td %>%\n  group_by(topic) %>%\n  slice_max(beta, n = 5) %>%\n  ungroup() %>%\n  arrange(topic, -beta)\n\ntop_terms\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_terms %>%\n  mutate(term = reorder_within(term, beta, topic)) %>%\n  ggplot(aes(term, beta)) +\n  geom_col() +\n  scale_x_reordered() +\n  facet_wrap(vars(topic), scales = \"free_x\")\n\n\nassignments <- augment(chapters_lda, data = chapters_dtm)\n\nassignments%>%\n  filter(!term==\"ladies\")\n\n# how words in titles changed overtime\ninaug_freq <- dat3 %>%\n  inner_join(dat2,by=c(\"chapter\",\"title\",\"going\"))%>%#View\n  count(time, word) %>%\n  complete(time, word, fill = list(n = 0)) %>%\n  group_by(time) %>%\n  mutate(time_total = sum(n), \n         percent = n / time_total) %>%\n  ungroup()\n\ninaug_freq\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(broom)\nmodels <- inaug_freq %>%\n  group_by(word) %>%\n  filter(sum(n) > 50) %>%\n  group_modify(\n    ~ tidy(glm(cbind(n, time_total - n) ~ time, ., \n               family = \"binomial\"))\n  ) %>%\n  ungroup() %>%\n  filter(term == \"time\")\n\nmodels\nmodels %>%\n  filter(term == \"time\") %>%\n  arrange(desc(abs(estimate)))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels %>%\n  mutate(adjusted.p.value = p.adjust(p.value)) %>%\n  ggplot(aes(estimate, adjusted.p.value)) +\n  geom_point(shape=\".\") +\n  #scale_y_log10() +\n  geom_text(aes(label = word), \n            #vjust = 1, hjust = 1, \n            check_overlap = TRUE) +\n  labs(x = \"Estimated change over time\", y = \"Adjusted p-value\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels %>%\n  slice_max(abs(estimate), n = 6) %>%\n  inner_join(inaug_freq) %>%\n  ggplot(aes(time, percent)) +\n  geom_point() +\n  geom_smooth() +\n  facet_wrap(vars(word)) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(y = \"Frequency of word in speech\")\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}