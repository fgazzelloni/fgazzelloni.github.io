{
  "hash": "984ff620ba8e0fb2051bbc404cebf8a0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Predictive modeling\"\nexcerpt: \"TidyModels vs Caret\"\nimage: featured.png\ndate: 2022-06-05\ndraft: false\nimages:\nseries:\ncategories: modeling\nlayout: single\nexecute: \n  eval: true\n---\n\n## Overview\n\nThis post is dedicated to make a comparison between **Caret** and **TidyModels** R packages. Data modelling with R pass through data preprocessing and parameters assessments to predicting an outcome. Both set of packages can be used to achieve same results, with the purpose of finding the best predictive performance for data specific models.\n\n![Predictive modeling - TreeMap](featured.png)\n\nThe **Caret** package is the starting point for understanding how to manage models and produce unbiases predictions with R. As well as **TidyModels** meta package, it gives the opportunity to contruct a multivariate model syntax to manage several models to be applied on same set of data. **TidyModels** allows the use of a set of concatenated functions in partership with the **TidyVerse** grammar to build a structural model base which blends different models as one global model.\n\nThe following is an attempt to a comparison between the two predictive model structures.\n\n------------------------------------------------------------------------\n\n## Caret package\n\nThe most important functions for this package, grouped by steps to modeling, are:\n\n1.  Preprocessing (data cleaning/wrangling)\n\n    -   preProcess()\n\n2.  Data splitting and resampling\n\n    -   createDataPartition()\n\n    ```{=html}\n    <!-- -->\n    ```\n    -    createResample()\n\n    -   createTimeSlices()\n\n3.  Model fit and prediction\n\n    -   train()\n\n    ```{=html}\n    <!-- -->\n    ```\n    -   predict()\n\n4.  Model comparison\n\n    -   confusionMatrix()\n\n------------------------------------------------------------------------\n\n# TidyModels meta package\n\nThis [\"meta package\"](https://tidymodels.tidymodels.org/) is made of a set of packages for modeling, with the support of other well known packages for data manipulation and visualization such as broom, dplyr, ggplot2, purrr, infer, modeldata, and tibble; it includes:\n\n-   recipes (a preprocessor)\n-   rsample (for resampling)\n-   parsnip (model syntax)\n-   tune and dials (optimization of hyperparameters)\n-   workflows and workflowsets (combine pre-processing steps and models)\n-   yardstick (for evaluating models)\n\nThe most important functions for this meta package, grouped by steps to modeling, are:\n\n1.  Preprocessing (data cleaning/wrangling)\n\n    -   recipes::recipe()\n\n    -   recipes::step\\_<functions>()\n\n2.  Data splitting and resampling\n\n    -   rsample::initial_split()\n\n    -   rsample::training()\n\n    -   rsample::testing()\n\n    -   rsample::bootstraps()\n\n    -   rsample::vfold_cv()\n\n    -    tune::control_resamples()\n\n3.  Model fit and prediction\n\n    -   parsnip::<model_type>() %\\>% set_mode() %\\>% set_engine()\n\n    -   parsnip::extract_fit_engine()\n\n    -   parsnip::extract_fit_parsnip()\n\n    -   parsnip::fit() stats::predict()\n\n    -   tune::fit_resamples()\n\n4.  Model workflow\n\n    -   workflows::workflow() %\\>% add_model()\n\n    -   workflows::add_formula()\n\n    -   workflows::add_recipe()\n\n    -   parsnip::fit()\n\n    -   stats::predict()\n\n    -   workflows::update_formula()\n\n    -   workflows::add_variables() / remove_variables()\n\n    -   workflowsets::workflow_set()\n\n    -   workflowsets::workflow_map()\n\n    -   workflowsets/tune::extract_workflow() / extract_recipe() / extract_fit_parsnip()\n\n    -   tune::last_fit()\n\n    -   workflowsets/tune::collect_metrics()\n\n    -   workflowsets/tune::collect_predictions()\n\n5.  Model comparison\n\n    -   yardstick::conf_mat()\n\n    -   yardstick::accuracy()\n\n    -   yardstick::metric_set()\n\n    -   yardstick::roc_curve()\n\n    -   yardstick::roc_auc()\n\n    -   yardstick::sensitivity()\n\n------------------------------------------------------------------------\n\n## Machine learning algorithms in R\n\n-   Linear discriminant analysis\n-   Regression\n-   Naive Bayes\n-   Support vector machines\n-   Classification and regression trees\n-   Random forests\n-   Boosting\n-   etc.\n\nResource: [Practical Machine Learning](https://github.com/DataScienceSpecialization/courses/tree/master/08_PracticalMachineLearning)\n\n------------------------------------------------------------------------\n\n## Caret or TidyModels?\n\n[Caret](http://caret.r-forge.r-project.org/) [Tidymodels](https://www.tidymodels.org/start/models/)\n\n------------------------------------------------------------------------\n\n## Caret Example with SPAM Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret); library(kernlab); data(spam)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ggplot2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'kernlab'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:ggplot2':\n\n    alpha\n```\n\n\n:::\n\n```{.r .cell-code}\ninTrain <- createDataPartition(y=spam$type,\n                              p=0.75, list=FALSE)\ntraining <- spam[inTrain,]\ntesting <- spam[-inTrain,]\n# dim(training)\n\nset.seed(32343)\nmodelFit <- train(type ~.,data=training, method=\"glm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: algorithm did not converge\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n\n\n:::\n\n```{.r .cell-code}\n# modelFit\n\npredictions <- predict(modelFit,newdata=testing)\n# predictions\n\ncm <- confusionMatrix(predictions,testing$type)\ncm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction nonspam spam\n   nonspam     655   37\n   spam         42  416\n                                          \n               Accuracy : 0.9313          \n                 95% CI : (0.9151, 0.9452)\n    No Information Rate : 0.6061          \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.8564          \n                                          \n Mcnemar's Test P-Value : 0.6527          \n                                          \n            Sensitivity : 0.9397          \n            Specificity : 0.9183          \n         Pos Pred Value : 0.9465          \n         Neg Pred Value : 0.9083          \n             Prevalence : 0.6061          \n         Detection Rate : 0.5696          \n   Detection Prevalence : 0.6017          \n      Balanced Accuracy : 0.9290          \n                                          \n       'Positive' Class : nonspam         \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(cm$table,main=\"Table\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n## TidyModels Example with SPAM Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tailor       0.1.0 \n✔ dplyr        1.1.4      ✔ tidyr        1.3.1 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.2.0      ✔ yardstick    1.3.2 \n✔ recipes      1.3.1      \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::alpha()          masks kernlab::alpha(), ggplot2::alpha()\n✖ dials::buffer()          masks kernlab::buffer()\n✖ rsample::calibration()   masks caret::calibration()\n✖ purrr::cross()           masks kernlab::cross()\n✖ purrr::discard()         masks scales::discard()\n✖ dplyr::filter()          masks stats::filter()\n✖ dplyr::lag()             masks stats::lag()\n✖ purrr::lift()            masks caret::lift()\n✖ yardstick::precision()   masks caret::precision()\n✖ yardstick::recall()      masks caret::recall()\n✖ yardstick::sensitivity() masks caret::sensitivity()\n✖ yardstick::specificity() masks caret::specificity()\n✖ recipes::step()          masks stats::step()\n```\n\n\n:::\n\n```{.r .cell-code}\ntidymodels_prefer()\nset.seed(123)\nsplit <- initial_split(spam,0.75,strata=type)\ntraining <- training(split)\ntesting <- testing(split)\n\nmodelFit <- logistic_reg() %>% \n  set_engine(\"glm\") %>%\n  fit(type~.,data=spam)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n\n\n:::\n\n```{.r .cell-code}\n# tidy(modelFit)\n\npredictions <- predict(modelFit,new_data=testing)\n# predictions\n\ntesting$pred <- predictions$.pred_class\ncm <- yardstick::conf_mat(data = testing, truth = type, estimate = pred)\ncm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction nonspam spam\n   nonspam     668   50\n   spam         29  404\n```\n\n\n:::\n\n```{.r .cell-code}\nautoplot(cm)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}